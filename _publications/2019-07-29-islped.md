---
title: "SECO: A Scalable Accuracy Approximate Exponential Function Via Cross-Layer Optimization"
collection: publications
permalink: /publication/2019-07-29-islped
excerpt:
date: 2019-07-29
venue: 'ISLPED'
paperurl:
citation:
---
[[Paper](https://diwu1990.github.io/files/islped2019_paper.pdf)] 
[[Poster](https://diwu1990.github.io/files/islped2019_poster.pdf)] 
[[Slide](https://diwu1990.github.io/files/islped2019_slide.pdf)] 
[[BibTex](https://diwu1990.github.io/files/islped2019_paper.bib)]

__Abstract:__

From signal processing to emerging deep neural networks, a range of applications exhibit intrinsic error resilience. For such applications, approximate computing opens up new possibilities for energy-efficient computing by producing slightly inaccurate results using greatly simplified hardware. Adopting this approach, a variety of basic arithmetic units, such as adders and multipliers, have been effectively redesigned to generate approximate results for many error-resilient applications. In this work, we propose SECO, an approximate exponential function unit (EFU). Exponentiation is a key operation in many signal processing applications and more importantly in spiking neuron models, but its energy-efficient implementation has been inadequately explored. We also introduce a cross-layer design method for SECO to optimize the energy-accuracy trade-off. At the algorithm level, SECO offers runtime scaling between energy efficiency and accuracy based on approximate Taylor expansion, where the error is minimized by optimizing parameters using discrete gradient descent at design time. At the circuit level, our error analysis method efficiently explores the design space to select the energy-accuracy-optimal approximate multiplier at design time. In tandem, the cross-layer design and runtime optimization method are able to generate energy-efficient and accurate approximate EFU designs that are up to 99.7% accurate at a power consumption of 3.73 pJ per exponential operation. SECO is also evaluated on the adaptive exponential integrate- and-fire neuron model, yielding only 0.002% timing error and 0.067% value error compared to the precise neuron model.